---
title: "MLM Workshop"
author: "Carla Martinez-Perez"
date: "2024-08-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Load data and dependencies
```{r setup, include=FALSE}
library("reshape2") #transform data from wide to long
library("tidyr") #for tidying messy data
library("dplyr") #for data manipulation
library("tidyverse")  #for data management
library("corrplot")    #for correlation plots
library("lme4") #for multilevel models
library("nlme") 
library("DHARMa")
library("optimx") #for model convergence 
library("Hmisc") #for variable clustering
library("emmeans") #for estimated marginal means (Helps interpreting LME models)
library("effects")
library("readxl") #for reading Excel files
library("gdata") #for interleave
library("ggplot2") #for data graphing/charting
library("MuMIn") #for model inference (AIC and BIC comparisons)
library("lmerTest") # Satterthwaite's approximation (p values for LME)
library("performance")

```
#######
Introduction 

**ID**            = participant ID

**Group**         = as stated - 2 experimental groups, 1 control group

**Phase**         = Reinforcement contingency in standard resurgence protocol

**Bin**   = nth minute of exposure to overall protocol - numbered such that last min of Phases 1 and 2 and first min of Phase 3 are 0 - this is to facilitate comparisons at those timepoints with emmeans          

**Rate**          = response rate 

**Bin.Normal**   = nth minute of exposure to overall protocol, numbered in ordinarily (e.g., 1-15)
``` {r transform file, include = TRUE}
#set wd
setwd()

#read .csv and convert long form
Data <- read.csv("/Users/cnmartinezperez/MLM Workshop/Data_wide.csv", header=TRUE)
View(Data)
data_long <- gather(Data, ID, Rate, P001:P151, factor_key=FALSE)
write.csv(data_long,"/Users/cnmartinezperez/MLM Workshop/Data_long.csv")
```

########
Methods

Participants = ~50 adults recruited via Prolific

Time         = 13.5 mins total (4.5-min phases)

Phases       = 3
- VI 2 Target: first 4.5 min 
- VI 2 Alt:    second 4.5 min
- EXT:        last 4.5 min 

### Analytical Strategy-MODEL 1

Within-subject factors: (random-intercept)
-Bin: nth minute of protocol 
-Phase: reinforcement contingency in place

Between-subject factor(s): (fixed effect)
  -Group
  -Phase
  _Bin
  
 Outcome:
  -Rate(s)

```{r import Target longform, include = TRUE}
#import target data - all Phases
##for this to work you need to go back to the csv files and add info (i.e., Group, Phase, Bin, Bin.Normal) to the columns
Data <-read.csv("/Users/cnmartinezperez/MLM Workshop/Data_long.csv")
Data$ID <- as.factor(Data$ID)
Data$Group <- as.factor(Data$Group)
Data$Phase <- as.factor(Data$Phase)
View(Data)
```

```{r Data Inspection}

#individual data, colored by group
Data %>% 
  ggplot(aes(x = Bin.Normal, 
             y = Rate,
             color=Group))+
  geom_line(aes(group = ID),
            linewidth   = 0.3)+
  geom_vline(xintercept = 9.25)+geom_vline(xintercept = 18.25)+
  theme_bw()

#group means + standard error
Data %>%
  group_by(Group, Phase, Bin.Normal) %>%
  dplyr::summarize(rawMeans = mean(Rate),
                   se   = sd(Rate)/sqrt(n())) %>%
  ggplot(aes(x = Bin.Normal, y = rawMeans, color=Group)) +
  geom_line() +
  geom_errorbar(aes(ymin = rawMeans - se, ymax = rawMeans + se))+
  geom_vline(xintercept = 9.25)+geom_vline(xintercept = 18.25)+
  theme_bw()

#-------

```
Now we run a null model to check for clustering. 

```{r Null Model}

Data_Empty <- lmer(Rate ~ 1 + (1 | ID), 
                           REML = FALSE,
                     data = Data)

#In this example, our null model contains the dependent variable "Rate" and we have fixed and random effect of the intercept (represented by the 1s). Our grouping variable is ID. The first 1 represents that we are evaluating the model at the overall mean of Rate. The (1|ID) means we want a random intercept at each level of ID (i.e., we want a random intercept for each participant)

summary(Data_Empty)
##Few things to consider here
#1. The log-likelihood measures how well the model fits the data; higher values (closer to zero) indicate a better fit.
#2. The estimate value of 14.47 indicates the overall mean of Rate across all IDs
#3. This is the p-value associated with the t-test for the fixed effect. It tests the null hypothesis that the intercept is zero. A very small p-value (much less than 0.05) indicates that the intercept is significantly different from zero.

#####Intraclass Correlation Coefficient

icc(Data_Empty)
 #About 8% of variance is due to differences between groups, while about 92% of variance is due to differences within groups.
#In mixed-effects models, an ICC of 8% still indicates that there is some clustering effect or group-level variance that should be accounted for in the model. Even a small ICC can justify using a mixed-effects model over a simple regression model if the group-level effect is significant.


```
Warrants a  linear mixed model: potentially...

Presumed maximal model:
  
1. Rate ~ Bin * Phase * Group + (Bin * Phase | ID) 

^^ this is based on previous research (i.e., theory). We know based on previous research that we would want to evaluate the predicting effects of Bin, Phase, and Group on the DV. What we vary, in this case, is the random effects. 

In lme4, the syntax for a two-level model is lmer(DV ~ 1 + IV1 + IV2 + ... + IVp + (random_effect1 + random_effect2 + ... + random_effect3 | grouping_variable), data = dataset).
Notice that the parameters are now conditional on Bin. The intercept is no longer interpreted as the intercept across all participants; itâ€™s the intercept across all participants conditional on Bin being equal to 0.

```{r RE Structure}
#if model cannot converge, change nlminb to L-BFGS-B
model1 = lmer(Rate ~ Bin * Phase * Group + (1 | ID),
              data = Data,
              REML = TRUE,
              control = lmerControl(optimizer = "optimx",
                                    calc.derivs = FALSE,
                                    optCtrl = list(method = "nlminb",
                                                   starttests = FALSE,
                                                   kkt = FALSE)))

model2 = lmer(Rate ~ Bin * Phase * Group + (Bin | ID),
              data = Data,
              REML = TRUE,
              control = lmerControl(optimizer = "optimx",
                                    calc.derivs = FALSE,
                                    optCtrl = list(method = "nlminb",
                                                   starttests = FALSE,
                                                   kkt = FALSE)))
model3 = lmer(Rate ~ Bin * Phase * Group + (Phase + Bin | ID),
              data = Data,
              REML = TRUE,
              control = lmerControl(optimizer = "optimx",
                                    calc.derivs = FALSE,
                                    optCtrl = list(method = "L-BFGS-B",
                                                   starttests = FALSE,
                                                   kkt = FALSE)))
#Compare models based on lowest AIC (best model)
AICc(model1,model2,model3)

bestmodel <- model3

```
If you get a "boundary (singular) fit: see help('isSingular')" warning, it means your model is singular. Singularity occurs when an element of your variance-covariance matrix is estimated as essentially zero as a result of extreme multicollinearity or because the parameter is actually essentially zero.
```{r Fixed Effects Significant}
#We evaluate the significance of our fixed effects using Wald tests with the best-fitting model. The test evaluates whether the fixed-effect parameters are significantly different from zero (or some other specified value). Moreover, the Wald test statistic follows a chi-squared distribution with degrees of freedom equal to the number of parameters being tested
car::Anova(bestmodel)

```
There are several assumptions for linear mixed effects models: 
 
1.The explanatory variables are related linearly to the response.
2.The errors in model predictions (i.e., model residuals) have constant variance. 
3.The errors are independent. 
4.The errors are normally distributed. 
```{r Assumptions_Residuals and Linearity}
library("moments")
library(boot)
library(DHARMa) # Both have model diagnostic tools for LME
library(ggplot2) # Charting
library(ggpubr)
library(knitr)
library(nlme)
library(vcdExtra)
library(aods3)
library(stringr)

#Checking residuals
res <- simulateResiduals(bestmodel, refit = F, n = 1000)

linearityDataFrame <- data.frame(Data$Rate, 
                                 res$fittedPredictedResponse)


#Normality plots
##Note: A clear pattern (e.g., curvature) suggests a violation of the linearity assumption.

##QQplot##
n <- length(res$scaledResiduals)
m <- (1:n)/(n + 1)
qqdataframe <- data.frame(m, res$scaledResiduals)
sx <- sort(qqdataframe$m)
sy <- sort(qqdataframe$res.scaledResiduals)
lenx <- length(sx)
leny <- length(sy)
if (leny < lenx) 
  sx <- approx(1L:lenx, sx, n = leny)$y
if (leny > lenx) 
  sy <- approx(1L:leny, sy, n = lenx)$y
Plot1 <- ggplot(qqdataframe, aes(x = sx, y = sy)) +
  geom_point(size = 4, shape = 1, stroke = 1.5) +
  xlab("Expected") +
  ylab("Observed") +
  xlim(0,1) +
  ylim(0,1) +
  geom_abline(intercept = 0, linewidth = 1.5, linetype = "dashed") +
  ggtitle("Q-Q Plot Residuals") + 
  theme_bw(base_size = 18) +
  theme(axis.text = element_text(color = "black"), 
        panel.grid = element_blank(), 
        panel.border = element_blank(), 
        axis.line = element_line(linewidth = 1), 
        axis.ticks = element_line(linewidth = 1), 
        plot.title = element_text(hjust = 0.5))

##Histogram of Residuals##
histdf <- data.frame(res$fittedResiduals)
Plot2 <- ggplot(histdf, aes(x = res$fittedResiduals)) + 
  geom_histogram(color = "black", fill = "lightgray", bins = 12) +
  #scale_x_continuous(limits = c(-2, 2), breaks = c(-2, -1, 0, 1, 2)) +
  #scale_x_continuous(limits = c(-2, 2)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_bw(base_size = 18) +
  ggtitle("Histogram of Residuals") +
  xlab("Residuals") +
  ylab("Count") +
  theme(axis.text = element_text(color = "black"), 
        panel.grid = element_blank(), 
        panel.border = element_blank(), 
        axis.line = element_line(linewidth = 1),
        axis.ticks = element_line(linewidth = 1), 
        plot.title = element_text(hjust = 0.5))

ggarrange(Plot1, Plot2,
          ncol = 2,
          nrow = 1)

#Normality tests (Shapiro-Wilk Test)
#Specifically designed to detect deviations from normality
shapiro.test(linearityDataFrame$res.fittedPredictedResponse)

```
We now begin to explore how the model predicts response rate by plotting
```{r Model Predictions}
#Checking residuals
Data$pred = predict(bestmodel)
Data$resid = resid(bestmodel)

Data %>%
  group_by(Group, Phase, Bin.Normal) %>%
  dplyr::summarize(predMean = mean(pred),
                   se   = sd(pred)/sqrt(n())) %>%
  ggplot(aes(x = Bin.Normal, y = predMean, color=Group)) +
  geom_line() +
  geom_errorbar(aes(ymin = predMean - se, ymax = predMean + se))+
  geom_vline(xintercept = 9.25)+geom_vline(xintercept = 18.25)+
  theme_bw()
```

Further explore the model while superimposed with the group and individual data.
```{r Probabilities, echo=FALSE, eval=TRUE}
#the group-level fits
Data$predg <- predict(bestmodel, type = "response", re.form = NA)

# The individual-level fits, as normal, are retained below
Data$predi <- predict(bestmodel, type = "response")

# Exploded out view
ggplot(Data, aes(
  x = Bin.Normal,
  y = predi,
  color = Group,
  group = ID
)) +
  ggtitle("Cross-Group Fixed Effects and Individual Variance") +
  geom_line(
    mapping = aes(
      x = Bin.Normal,
      y = predg,
      group = Group
    ),
  linewidth = 1.5,
    color = "black"
  ) +
  xlab("Bin") +
  ylab("Responses") +
  geom_line(alpha = 0.25) +
  geom_vline(xintercept = 9.5) +
  geom_vline(xintercept = 18.5) +
  theme_bw() +
  facet_wrap(~Group, nrow = 4) +
  theme(legend.position = "bottom")

# Exploded out view
ggplot(Data, aes(
  x = Bin.Normal,
  y = predi,
  color = Group,
  group = ID
)) +
  ggtitle("Collapsed Fixed Effects and Individual Variance") +
  geom_line(
    mapping = aes(
      x = Bin.Normal,
      y = predg,
      color = Group,
      group = Group
    ),
    linewidth = 2
  ) +
  xlab("Bin") +
  ylab("Responses") +
  geom_line(alpha = 0.125) +
  geom_vline(xintercept = 9.5) +
  geom_vline(xintercept = 18.5) +
  theme_bw() +
  theme(legend.position = "bottom")
```
Lastly, call a summary of the model. This will guide your interpretation of the data. 
```{r Model Results and Interpretations}
summary(bestmodel)

#To Calculate effect sizes (d) of significant fixed effects using Westfall et al. (2014)'s method. 
#Essentially, we are calculating the square root of the sum of the variance of the random effects and then divided the fixed effect estimate by that value. 

#sqrt(intercept + RE1 + RE2)
#XX.XX
#print(ES <- FE/XX.XX)
```

```{r Post Hoc Comparisons}
#...looking @ last bin in Phases 1 and 2, first bin of Phase 3-- all coded '0'
#between-phases for each group 
emmeans::emmeans(bestmodel, pairwise~Phase|Bin|Group, adjust="none", at = list(Bin = c(0)),pbkrtest.limit = 5025)

emmeans::emmeans(bestmodel, pairwise~Group|Bin|Phase, adjust="none", at = list(Bin = c(0)),pbkrtest.limit = 5025)
```

